---
title: ura
published: true

# date: 06-01-2018
date_txt: "Dec 2018"
subtitle_txt: "Adversarial Attacks and Saliency"
tag_txt: "technical"
order: 10

image_list:
  - img_txt: "../assets/images/portfolio/ura/saliency.png"
  - img_txt: "../assets/images/portfolio/ura/no_mask.png"
  - img_txt: "../assets/images/portfolio/ura/saliency_mask.png"
  - img_txt: "../assets/images/portfolio/ura/inv_mask.png"

paragraph_txt: "The idea behind this research project is to determine if it is possible to maintain the adversity of attacks while decreasing their detectabilty through masking attacks with interperability maps. There are many methods of generating adversarial noise on images that can inhibit classifiers' ability to determine the identity of the image - however, the question of the methods' detectability still remains. Through masking noise with saliency maps, it is possible to still produce severe attacks while reducing visual detectability because less noise is applied, but that noise targets significant areas. </br></br> Below are a sample of a saliency map, adversarial noise, adversarial noise masked with a saliency map, and adversarial noised masked with the inverse of a saliency map."
---






